## AI分析任务设计总纲：从分析范式到LLM执行指南

**核心目标：** 本文档定义了一套顶层方法论，其最终产出**不是分析报告本身**，而是用于指导开发者构建高质量、可复用分析模块的**“分析任务设计文档”**（`Analysis Guide`）。

遵循此范式，我们可以将复杂的分析目标，系统性地拆解为一系列结构化的、由LLM驱动的分析模块。其最终交付物是一个清晰、可执行的开发指南，**其形态应参考 `docs/market_analysis_guide.md`**。该指南将包含针对每个分析模块的具体Prompt、输入/输出（I/O）定义和JSON模板。

简而言之，此范式是“授人以渔”，而非“授人以鱼”。它指导我们如何**设计**能让LLM稳定输出高质量分析的**任务**。

---

### 一、核心哲学：LLM分析的基石

这是成功设计出能驱动LLM进行高质量数据分析的任务的四个基本原则。

1.  **数据为王，杜绝外部信息 (Data-Driven Purity)**
    *   **核心：** 强约束LLM的所有分析都必须严格、唯一地基于所提供的原始数据。严禁其引用任何无法从数据中直接验证的外部知识（如新闻、个人经验等）。
    *   **价值：** 这将LLM的角色从一个“知识检索工具”转变为一个纯粹的“模式识别与逻辑推理引擎”。它迫使LLM深入数据内部，去发现事实和关系，而不是对数据进行外部的、想当然的解读。

2.  **LLM作为洞察引擎 (LLM as an Insight Engine)**
    *   **核心：** 将LLM的核心价值定位在高级认知任务上，而非简单的数据处理。这些任务包括：发现数据点之间的非线性关联、总结复杂的现象、构建有说服力的逻辑链条和市场叙事。
    *   **价值：** 让LLM做人类分析师最耗时、最依赖灵感的工作，从而大规模、系统性地产生高质量的洞察。

3.  **原始数据价值最大化 (Maximizing Value from Raw Data)**
    *   **核心：** 尽可能向LLM提供完整、未经过滤的原始数据集。避免在代码层面对数据进行预先筛选、聚合或简化。
    *   **价值：** 预处理会不经意间丢失关键上下文或异常信号。让LLM直面最完整的数据，使其能够在全局视角下自行完成信息的筛选、权衡和关联，从而发现人类可能忽略的、非预期的模式。这是V2版指南中的关键升级。

4.  **代码构筑框架，LLM填充灵魂 (Code Builds the Frame, LLM Fills the Soul)**
    *   **核心：** 在最终的`Analysis Guide`中，我们必须进行明确的责任划分。代码负责“管道工程”：定义分析流程、管理数据I/O、调用LLM接口，并确保最终输出格式的稳定。LLM则负责填充框架内的“血肉”：产出所有分析性、判断性和叙事性的内容。
    *   **价值：** 这种划分确保了最终实现的系统兼具工程的稳定性与分析的创造力。

---

### 二、分析指南设计：三步法构建分析模块

这是一个将复杂问题分解，并最终形成`Analysis Guide`中各个分析模块的结构化流程。

1.  **模块化分解 (Modular Decomposition)**
    *   **做法：** 将一个笼统的分析目标（例如“分析销售数据”）分解为几个独立的、目标明确的分析模块。每个模块都应该旨在回答一个关于数据的、高层次的核心问题。
    *   **案例：** 将“分析用户行为数据”分解为：“用户活跃度变迁分析”、“高价值用户群体画像”、“用户流失关键原因识别”三个模块。

2.  **递进式分析 (Progressive Analysis)**
    *   **做法：** 设计的分析模块应遵循一种递进关系，引导LLM从识别表面现象，到剖析内部结构，再到构建深层逻辑。这种层层深入的分析路径，确保了洞察的深度和质量。
    *   **逻辑层次：**
        *   **表层（现象）：** 发生了什么？（例：用户增长了）
        *   **中层（结构）：** 增长的质量如何？（例：是哪些渠道、哪些用户在增长？）
        *   **深层（叙事）：** 为什么会发生？

3.  **标准化输出 (Standardized Output)**
    *   **做法：** 为每个分析模块强制规定一个严格的、机器可读的输出格式（强烈推荐JSON）。并提供一个包含占位符的清晰模板。
    *   **价值：** 确保LLM输出的确定性和可用性，便于下游程序（如报告生成、数据可视化）的无缝集成。

---

### 三、高效Prompt工程：为分析模块注入“专家之魂”

这是一套用于在`Analysis Guide`中，为每个分析模块构建高质量Prompt的最佳实践。

1.  **赋予专家角色 (Assign an Expert Persona)**
    *   **格式：** `你是一位[领域]的顶尖[角色]，例如：世界级的商业数据分析师、经验丰富的用户行为研究专家...`
    *   **目的：** 快速设定LLM的语境、口吻和分析视角。

2.  **明确核心任务 (Define the Core Mission)**
    *   **格式：** `你的核心任务是，基于下方的数据，[你的核心分析目标]，例如：识别出市场的主导趋势、诊断用户流失的根本原因...`
    *   **目的：** 给出清晰的、唯一的任务指令。

3.  **设定关键原则与约束 (Set Key Principles & Constraints)**
    *   **格式：** `重要原则：你的所有分析都必须严格基于下方提供的数据，严禁引入任何数据之外的、无法验证的外部信息...`
    *   **目的：** 奠定“数据为王”的分析基调，规避LLM“幻觉”。

4.  **提供结构化分析步骤 (Provide Structured Analytical Steps)**
    *   **格式：** 以数字列表的形式，清晰地列出LLM需要遵循的思考和分析路径。这通常与“递进式分析流”中的步骤相对应。
    *   **目的：** 将一个复杂的认知任务，分解为LLM可以稳定执行的、连续的子任务，引导其思考过程。

5.  **指明关键数据维度 (Point to Key Data Dimensions)**
    *   **格式：** 在每个分析步骤中，明确提示LLM应该重点关注哪些数据字段，以及如何对它们进行比较和解读。
    *   **案例：** `在第一步中，请重点关注`rank`（排名）和`rank_change`（排名变化）字段。在第二步中，请结合`metric_A`和`metric_B`来评估其健康度...`
    *   **目的：** 帮助LLM在海量数据中快速定位到最有价值的信息。

6.  **指定输出格式 (Demand Structured Output)**
    *   **格式：** `请将你的完整分析，以结构化的JSON格式输出，并严格遵循下方的模板...`
    *   **目的：** 获取稳定、可靠、可供程序调用的最终结果。 