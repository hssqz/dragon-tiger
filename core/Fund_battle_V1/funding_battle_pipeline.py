"""
é¾™è™æ¦œèµ„é‡‘åšå¼ˆåˆ†æ - ä¸»æµç¨‹æ§åˆ¶å™¨
æ•´åˆä¸‰ä¸ªé˜¶æ®µçš„å¤„ç†æµç¨‹ï¼šä»£ç é¢„å¤„ç† -> LLMå¢å¼º -> å™äº‹ç”Ÿæˆ
"""

import os
import json
import logging
from typing import Dict, List, Any, Optional
from pathlib import Path
from datetime import datetime

# æ™ºèƒ½å¯¼å…¥å¤„ç†
try:
    from core.funding_battle_builder import FundingBattleBuilder
    from core.funding_battle_enricher import FundingBattleEnricher
    from core.Fund_build_V1.post_generator import PostGenerator
    from core.deepseek_interface import DeepSeekInterface
except ImportError:
    from funding_battle_builder import FundingBattleBuilder
    from funding_battle_enricher import FundingBattleEnricher
    from core.Fund_build_V1.post_generator import PostGenerator
    from deepseek_interface import DeepSeekInterface

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger('funding_battle_pipeline')

class FundingBattlePipeline:
    """
    é¾™è™æ¦œèµ„é‡‘åšå¼ˆåˆ†ææµæ°´çº¿
    æ•´åˆä¸‰ä¸ªé˜¶æ®µï¼šäº‹å®å±‚ -> æ´å¯Ÿå±‚ -> å™äº‹å±‚
    """
    
    def __init__(self, deepseek_interface: Optional[DeepSeekInterface] = None):
        """
        åˆå§‹åŒ–åˆ†ææµæ°´çº¿
        
        å‚æ•°:
            deepseek_interface: DeepSeekæ¥å£å®ä¾‹ï¼Œå¦‚æœä¸æä¾›åˆ™è‡ªåŠ¨åˆ›å»º
        """
        logger.info("åˆå§‹åŒ–é¾™è™æ¦œèµ„é‡‘åšå¼ˆåˆ†ææµæ°´çº¿")
        
        # åˆå§‹åŒ–ä¸‰ä¸ªé˜¶æ®µçš„å¤„ç†å™¨
        self.builder = FundingBattleBuilder()
        self.enricher = FundingBattleEnricher(deepseek_interface)
        self.generator = PostGenerator(deepseek_interface)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.ensure_output_directories()
    
    def ensure_output_directories(self):
        """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
        directories = [
            "data/processed",
            "data/output/posts",
            "data/output/summaries"
        ]
        
        for dir_path in directories:
            os.makedirs(dir_path, exist_ok=True)
            logger.debug(f"ç¡®ä¿ç›®å½•å­˜åœ¨: {dir_path}")
    
    def generate_file_names(self, stock_name: str, ts_code: str) -> Dict[str, str]:
        """
        ç”Ÿæˆå„é˜¶æ®µè¾“å‡ºæ–‡ä»¶å
        
        å‚æ•°:
            stock_name(str): è‚¡ç¥¨åç§°
            ts_code(str): è‚¡ç¥¨ä»£ç 
            
        è¿”å›:
            Dict[str, str]: å„é˜¶æ®µæ–‡ä»¶è·¯å¾„
        """
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # æ¸…ç†è‚¡ç¥¨åç§°ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦
        clean_name = "".join(c for c in stock_name if c.isalnum() or c in "._-")
        clean_code = ts_code.replace(".", "_")
        
        base_name = f"{timestamp}_{clean_name}_{clean_code}"
        
        return {
            "structured_facts": f"data/processed/{base_name}_structured_facts.json",
            "funding_summary": f"data/processed/{base_name}_funding_summary.json",
            "analysis_report": f"data/output/posts/{base_name}_analysis_report.md",
            "summary_copy": f"data/output/summaries/{base_name}_summary.json"
        }
    
    def run_stage1_facts_extraction(self, input_path: str, output_path: str) -> bool:
        """
        è¿è¡Œç¬¬ä¸€é˜¶æ®µï¼šäº‹å®æå–ï¼ˆä»£ç é¢„å¤„ç†ï¼‰
        
        å‚æ•°:
            input_path(str): åŸå§‹æ•°æ®è·¯å¾„
            output_path(str): ç»“æ„åŒ–äº‹å®è¾“å‡ºè·¯å¾„
            
        è¿”å›:
            bool: æ˜¯å¦æˆåŠŸ
        """
        logger.info("ğŸ”„ å¼€å§‹ç¬¬ä¸€é˜¶æ®µï¼šäº‹å®æå–ï¼ˆä»£ç é¢„å¤„ç†ï¼‰")
        
        success = self.builder.process_file(input_path, output_path)
        
        if success:
            logger.info("âœ… ç¬¬ä¸€é˜¶æ®µå®Œæˆï¼šç»“æ„åŒ–äº‹å®æ•°æ®å·²ç”Ÿæˆ")
        else:
            logger.error("âŒ ç¬¬ä¸€é˜¶æ®µå¤±è´¥ï¼šäº‹å®æå–å¤±è´¥")
        
        return success
    
    def run_stage2_llm_enhancement(self, input_path: str, output_path: str) -> bool:
        """
        è¿è¡Œç¬¬äºŒé˜¶æ®µï¼šLLMæ´å¯Ÿå¢å¼º
        
        å‚æ•°:
            input_path(str): ç»“æ„åŒ–äº‹å®æ•°æ®è·¯å¾„
            output_path(str): å¢å¼ºæ‘˜è¦è¾“å‡ºè·¯å¾„
            
        è¿”å›:
            bool: æ˜¯å¦æˆåŠŸ
        """
        logger.info("ğŸ”„ å¼€å§‹ç¬¬äºŒé˜¶æ®µï¼šLLMæ´å¯Ÿå¢å¼º")
        
        success = self.enricher.process_file(input_path, output_path)
        
        if success:
            logger.info("âœ… ç¬¬äºŒé˜¶æ®µå®Œæˆï¼šLLMå¢å¼ºåˆ†æå·²å®Œæˆ")
        else:
            logger.error("âŒ ç¬¬äºŒé˜¶æ®µå¤±è´¥ï¼šLLMå¢å¼ºå¤±è´¥")
        
        return success
    
    def run_stage3_narrative_generation(self, input_path: str, output_path: str) -> bool:
        """
        è¿è¡Œç¬¬ä¸‰é˜¶æ®µï¼šå™äº‹ç”Ÿæˆ
        
        å‚æ•°:
            input_path(str): å¢å¼ºæ‘˜è¦æ•°æ®è·¯å¾„
            output_path(str): åˆ†ææŠ¥å‘Šè¾“å‡ºè·¯å¾„
            
        è¿”å›:
            bool: æ˜¯å¦æˆåŠŸ
        """
        logger.info("ğŸ”„ å¼€å§‹ç¬¬ä¸‰é˜¶æ®µï¼šå™äº‹ç”Ÿæˆ")
        
        success = self.generator.process_file(input_path, output_path)
        
        if success:
            logger.info("âœ… ç¬¬ä¸‰é˜¶æ®µå®Œæˆï¼šåˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ")
        else:
            logger.error("âŒ ç¬¬ä¸‰é˜¶æ®µå¤±è´¥ï¼šæŠ¥å‘Šç”Ÿæˆå¤±è´¥")
        
        return success
    
    def run_full_pipeline(self, input_path: str, output_dir: str = None) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„ä¸‰é˜¶æ®µåˆ†ææµæ°´çº¿
        
        å‚æ•°:
            input_path(str): åŸå§‹é¾™è™æ¦œæ•°æ®è·¯å¾„
            output_dir(str): è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®çš„ç›®å½•
            
        è¿”å›:
            Dict[str, Any]: è¿è¡Œç»“æœå’Œè¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        logger.info("ğŸš€ å¼€å§‹è¿è¡Œå®Œæ•´çš„é¾™è™æ¦œèµ„é‡‘åšå¼ˆåˆ†ææµæ°´çº¿")
        logger.info(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {input_path}")
        
        result = {
            "success": False,
            "stages_completed": 0,
            "output_files": {},
            "error_message": "",
            "processing_time": 0
        }
        
        start_time = datetime.now()
        
        try:
            # è¯»å–åŸå§‹æ•°æ®è·å–è‚¡ç¥¨ä¿¡æ¯
            with open(input_path, 'r', encoding='utf-8') as f:
                raw_data = json.load(f)
            
            stocks = raw_data.get("stocks", [])
            if not stocks:
                result["error_message"] = "åŸå§‹æ•°æ®ä¸­æœªæ‰¾åˆ°è‚¡ç¥¨ä¿¡æ¯"
                return result
            
            stock_data = stocks[0]
            stock_name = stock_data.get("name", "æœªçŸ¥è‚¡ç¥¨")
            ts_code = stock_data.get("ts_code", "UNKNOWN")
            
            logger.info(f"ğŸ“Š åˆ†æç›®æ ‡: {stock_name} ({ts_code})")
            
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
            file_paths = self.generate_file_names(stock_name, ts_code)
            result["output_files"] = file_paths
            
            # ç¬¬ä¸€é˜¶æ®µï¼šäº‹å®æå–
            stage1_success = self.run_stage1_facts_extraction(
                input_path, 
                file_paths["structured_facts"]
            )
            
            if not stage1_success:
                result["error_message"] = "ç¬¬ä¸€é˜¶æ®µäº‹å®æå–å¤±è´¥"
                return result
            
            result["stages_completed"] = 1
            
            # ç¬¬äºŒé˜¶æ®µï¼šLLMå¢å¼º
            stage2_success = self.run_stage2_llm_enhancement(
                file_paths["structured_facts"],
                file_paths["funding_summary"]
            )
            
            if not stage2_success:
                result["error_message"] = "ç¬¬äºŒé˜¶æ®µLLMå¢å¼ºå¤±è´¥"
                return result
            
            result["stages_completed"] = 2
            
            # ç¬¬ä¸‰é˜¶æ®µï¼šå™äº‹ç”Ÿæˆ
            stage3_success = self.run_stage3_narrative_generation(
                file_paths["funding_summary"],
                file_paths["analysis_report"]
            )
            
            if not stage3_success:
                result["error_message"] = "ç¬¬ä¸‰é˜¶æ®µå™äº‹ç”Ÿæˆå¤±è´¥"
                return result
            
            result["stages_completed"] = 3
            
            # å¤åˆ¶æ‘˜è¦åˆ°è¾“å‡ºç›®å½•
            self.copy_summary_to_output(
                file_paths["funding_summary"],
                file_paths["summary_copy"]
            )
            
            result["success"] = True
            
            end_time = datetime.now()
            result["processing_time"] = (end_time - start_time).total_seconds()
            
            logger.info("ğŸ‰ å®Œæ•´æµæ°´çº¿è¿è¡ŒæˆåŠŸï¼")
            logger.info(f"â±ï¸ æ€»è€—æ—¶: {result['processing_time']:.1f}ç§’")
            
        except Exception as e:
            result["error_message"] = f"æµæ°´çº¿è¿è¡Œå¼‚å¸¸: {str(e)}"
            logger.error(f"âŒ æµæ°´çº¿è¿è¡Œå¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
        
        return result
    
    def copy_summary_to_output(self, source_path: str, target_path: str):
        """
        å¤åˆ¶æ‘˜è¦æ–‡ä»¶åˆ°è¾“å‡ºç›®å½•
        
        å‚æ•°:
            source_path(str): æºæ–‡ä»¶è·¯å¾„
            target_path(str): ç›®æ ‡æ–‡ä»¶è·¯å¾„
        """
        try:
            with open(source_path, 'r', encoding='utf-8') as f:
                content = json.load(f)
            
            with open(target_path, 'w', encoding='utf-8') as f:
                json.dump(content, f, ensure_ascii=False, indent=2)
            
            logger.info(f"æ‘˜è¦æ–‡ä»¶å·²å¤åˆ¶åˆ°è¾“å‡ºç›®å½•: {target_path}")
            
        except Exception as e:
            logger.warning(f"å¤åˆ¶æ‘˜è¦æ–‡ä»¶å¤±è´¥: {e}")
    
    def print_result_summary(self, result: Dict[str, Any]):
        """
        æ‰“å°è¿è¡Œç»“æœæ‘˜è¦
        
        å‚æ•°:
            result(Dict): è¿è¡Œç»“æœ
        """
        print("\n" + "="*60)
        print("ğŸ¯ é¾™è™æ¦œèµ„é‡‘åšå¼ˆåˆ†ææµæ°´çº¿ - è¿è¡Œç»“æœ")
        print("="*60)
        
        if result["success"]:
            print("âœ… çŠ¶æ€: è¿è¡ŒæˆåŠŸ")
            print(f"âš¡ å®Œæˆé˜¶æ®µ: {result['stages_completed']}/3")
            print(f"â±ï¸ æ€»è€—æ—¶: {result['processing_time']:.1f}ç§’")
            
            print("\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
            for file_type, file_path in result["output_files"].items():
                if os.path.exists(file_path):
                    file_size = os.path.getsize(file_path)
                    print(f"  âœ“ {file_type}: {file_path} ({file_size} bytes)")
                else:
                    print(f"  âœ— {file_type}: {file_path} (æ–‡ä»¶ä¸å­˜åœ¨)")
            
        else:
            print("âŒ çŠ¶æ€: è¿è¡Œå¤±è´¥")
            print(f"âš¡ å®Œæˆé˜¶æ®µ: {result['stages_completed']}/3")
            print(f"ğŸ’¥ é”™è¯¯ä¿¡æ¯: {result['error_message']}")
        
        print("="*60 + "\n")


# ====== ä¸»ç¨‹åºå…¥å£ ======
def main():
    """ä¸»ç¨‹åºå…¥å£"""
    # åˆ›å»ºæµæ°´çº¿
    pipeline = FundingBattlePipeline()
    
    # é»˜è®¤è¾“å…¥æ–‡ä»¶
    default_input = "core/test-seat.json"
    
    print("ğŸš€ é¾™è™æ¦œèµ„é‡‘åšå¼ˆåˆ†ææµæ°´çº¿")
    print(f"ğŸ“ ä½¿ç”¨é»˜è®¤è¾“å…¥æ–‡ä»¶: {default_input}")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(default_input):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {default_input}")
        return
    
    # è¿è¡Œå®Œæ•´æµæ°´çº¿
    result = pipeline.run_full_pipeline(default_input)
    
    # æ‰“å°ç»“æœæ‘˜è¦
    pipeline.print_result_summary(result)
    
    # å¦‚æœæˆåŠŸï¼Œå°è¯•æ˜¾ç¤ºæŠ¥å‘Šé¢„è§ˆ
    if result["success"] and "analysis_report" in result["output_files"]:
        report_path = result["output_files"]["analysis_report"]
        if os.path.exists(report_path):
            try:
                with open(report_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                print("ğŸ“„ åˆ†ææŠ¥å‘Šé¢„è§ˆï¼ˆå‰800å­—ç¬¦ï¼‰:")
                print("-" * 60)
                print(content[:800] + "..." if len(content) > 800 else content)
                print("-" * 60)
                
            except Exception as e:
                print(f"âŒ è¯»å–æŠ¥å‘Šé¢„è§ˆå¤±è´¥: {e}")


if __name__ == "__main__":
    main() 