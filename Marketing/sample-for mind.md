

AI没有能力计算到「机会成本」这个巨大缝隙，起码基于目前的Transformer架构不行，因为这本来就是怪事。没有在真实世界发生过的语料根本就不存在发生，AI又能怎么被训练到呢？
如果真的像文中可以所说，即使在prompt中强制要求只根据图片回答，不要凭印象，对于5条腿的狮子、3条脚的鸟、5条腿的大象、3只脚的鸭子、5条狗的腿。6根手指图片的可怜的平均准确率，只有2.12%。100次，才对2次。
那么，也就意味着发生在真实世界的【常识】的引力太过沉重。如果盲目听从AI的指引将可能是锁死人类自己的黑域

Harj Tagger 引用了经济学家 Bryan Caplan 的一个理论：传统教育，尤其是名校教育，本质上是在为雇主提供一种「资质证明」：
它证明毕业生能够「按时出现、执行一系列指令、不过度放纵，并顺利毕业」。

能上LLM就上LLM，绝对不用Code
可控性配上一个json output也够了
做好上下文压缩，智能是最大的杠杆

巴菲特说，如果你知道了能力圈的边界所在，你将比那些能力圈虽然比你大五倍，却不知道边界所在的人要富有得多。
前者比后者难得多的原因是：后者只顾前进就可以了，而前者需要在边界所在之处反复拉扯，突破，假突破，回退，再尝试发起冲锋，再次失败。反复割据，最终才能知道自己能力圈的边界。